{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590de603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload automatically when the file is changed.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942a6de",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79034fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "from sklearn import (linear_model, model_selection, preprocessing,\n",
    "                     pipeline)\n",
    "from scipy.spatial.distance import pdist\n",
    "from kymatio.torch import HarmonicScattering3D\n",
    "from kymatio.scattering3d.utils import generate_weighted_sum_of_gaussians\n",
    "from kymatio.datasets import fetch_qm7\n",
    "from kymatio.caching import get_cache_dir\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "# Import torch backend \n",
    "from kymatio.scattering3d.backend.torch_backend import TorchBackend3D\n",
    "\n",
    "import os \n",
    "import sys\n",
    "MODULES_PATH = \"../../Modules/Scattering\"\n",
    "MODELS_PATH = \"../../Models/\"\n",
    "\n",
    "sys.path.append(MODULES_PATH)\n",
    "sys.path.append(MODELS_PATH)\n",
    "\n",
    "\n",
    "from Preprocessing import *\n",
    "from Dataloaders_Preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8f78f",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Data_Train = Load_Data('../../Data/atoms/train', '../../Data/energies/train.csv')\n",
    "List_Data_Test= Load_Test_Data('../../Data/atoms/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Data_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4712c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Display_Molecule_From_Atom_List(List_Data_Train[500]['Atoms_List'], Width=800, Height=800, Background_Color='lightblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefa987",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dataset = XYZDataset_V2(List_Data_Train)\n",
    "Test_Dataset = XYZDataset_V2(List_Data_Test,return_energy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307fe52",
   "metadata": {},
   "source": [
    "# Scattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f53ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SCATTERING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd540ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(device):\n",
    "    M = 192\n",
    "    N = 128\n",
    "    O = 96\n",
    "    grid  = torch.tensor(np.fft.ifftshift(np.mgrid[-M//2:-M//2+M, -N//2:-N//2+N, -O//2:-O//2+O]))\n",
    "    \n",
    "    J =2\n",
    "    L = 3\n",
    "    sigma = 2.0\n",
    "    integral_powers = [0.5, 1.0, 2.0, 3.0,5.0]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    scattering = HarmonicScattering3D(J=J, shape=(M, N, O),\n",
    "                                        L=L, sigma_0=sigma,\n",
    "                                        integral_powers=integral_powers, max_order=2).to(device)\n",
    "    \n",
    "    return grid, scattering, sigma, integral_powers, M,N,O,J,L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833db010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory and ensure it exists\n",
    "output_dir_train = \"../../Saved_Features/Scattering/Train\"\n",
    "os.makedirs(output_dir_train, exist_ok=True)\n",
    "\n",
    "output_dir_test = \"../../Saved_Features/Scattering/Test\"\n",
    "os.makedirs(output_dir_test, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SCATTERING:\n",
    "\n",
    "    order_0, orders_1_and_2 = [], []\n",
    "    Ids = []\n",
    "    energies = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    grid, scattering, sigma, integral_powers, M,N,O,J,L = config(device)\n",
    "\n",
    "    test_loader = DataLoader(Test_Dataset, batch_size=16, shuffle=True)\n",
    "    train_loader = DataLoader(Train_Dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "    import torch\n",
    "    from tqdm.auto import tqdm\n",
    "    import os\n",
    "\n",
    "    # Assuming order_0, orders_1_and_2, and energies are lists\n",
    "    order_0 = []\n",
    "    orders_1_and_2 = []\n",
    "    energies = []\n",
    "\n",
    "    # Your existing loop\n",
    "    for batch in tqdm(train_loader):\n",
    "        Id_Batch = batch[0]\n",
    "        full_charge_batch = batch[1]\n",
    "        valence_batch = batch[2]\n",
    "        pos_batch = batch[3]\n",
    "        energie = batch[4]\n",
    "\n",
    "        full_density_batch = generate_weighted_sum_of_gaussians(grid, pos_batch, full_charge_batch, sigma)\n",
    "        full_density_batch = torch.from_numpy(full_density_batch)\n",
    "        full_density_batch = full_density_batch.to(device).float()\n",
    "        full_order_0 = TorchBackend3D.compute_integrals(full_density_batch, integral_powers)\n",
    "        full_scattering = scattering(full_density_batch)\n",
    "\n",
    "        val_density_batch = generate_weighted_sum_of_gaussians(grid, pos_batch, valence_batch, sigma)\n",
    "        val_density_batch = torch.from_numpy(val_density_batch)\n",
    "        val_density_batch = val_density_batch.to(device).float()\n",
    "        val_order_0 = TorchBackend3D.compute_integrals(val_density_batch, integral_powers)\n",
    "        val_scattering = scattering(val_density_batch)\n",
    "\n",
    "        core_density_batch = full_density_batch - val_density_batch\n",
    "        core_order_0 = TorchBackend3D.compute_integrals(core_density_batch, integral_powers)\n",
    "        core_scattering = scattering(core_density_batch)\n",
    "\n",
    "        batch_order_0 = torch.stack((full_order_0, val_order_0, core_order_0), dim=-1)\n",
    "        batch_orders_1_and_2 = torch.stack((full_scattering, val_scattering, core_scattering), dim=-1)\n",
    "        \n",
    "        order_0.append(batch_order_0)\n",
    "        orders_1_and_2.append(batch_orders_1_and_2)\n",
    "        energies.append(energie)\n",
    "        Ids.append(Id_Batch)\n",
    "else:\n",
    "    order_0_train = torch.load(os.path.join(output_dir_train, 'order_0.pt'))\n",
    "    orders_1_and_2_train = torch.load(os.path.join(output_dir_train, 'orders_1_and_2.pt'))\n",
    "    energies_train = torch.load(os.path.join(output_dir_train, 'energies.pt'))\n",
    "    Ids_train = torch.load(os.path.join(output_dir_train, 'Ids.pt'))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SCATTERING:\n",
    "    # After the loop, concatenate the lists into single tensors\n",
    "    order_0_train = torch.cat(order_0, dim=0)  # Adjust dim as needed\n",
    "    orders_1_and_2_train = torch.cat(orders_1_and_2, dim=0)  # Adjust dim as needed\n",
    "    energies_train = torch.cat(energies, dim=0)  # Adjust dim as needed\n",
    "    Ids_train = torch.cat(Ids, dim=0)  # Adjust dim as needed\n",
    "\n",
    "    # Save tensors to files\n",
    "    torch.save(order_0_train, os.path.join(output_dir_train, \"order_0.pt\"))\n",
    "    torch.save(orders_1_and_2_train, os.path.join(output_dir_train, \"orders_1_and_2.pt\"))\n",
    "    torch.save(energies_train, os.path.join(output_dir_train, \"energies.pt\"))\n",
    "\n",
    "    # Save Ids\n",
    "    torch.save(Ids_train, os.path.join(output_dir_train, \"Ids.pt\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ccc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SCATTERING:\n",
    "    order_0, orders_1_and_2 = [], []\n",
    "    energies = []\n",
    "    Ids = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    grid, scattering, sigma, integral_powers, M,N,O,J,L = config(device)\n",
    "\n",
    "    test_loader = DataLoader(Test_Dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "    import torch\n",
    "    from tqdm.auto import tqdm\n",
    "    import os\n",
    "\n",
    "    # Assuming order_0, orders_1_and_2, and energies are lists\n",
    "    order_0 = []\n",
    "    orders_1_and_2 = []\n",
    "    energies = []\n",
    "\n",
    "    # Your existing loop\n",
    "    for batch in tqdm(test_loader):\n",
    "        Id_batch = batch[0]\n",
    "        full_charge_batch = batch[1]\n",
    "        valence_batch = batch[2]\n",
    "        pos_batch = batch[3]\n",
    "        energie = 0\n",
    "\n",
    "        full_density_batch = generate_weighted_sum_of_gaussians(grid, pos_batch, full_charge_batch, sigma)\n",
    "        full_density_batch = torch.from_numpy(full_density_batch)\n",
    "        full_density_batch = full_density_batch.to(device).float()\n",
    "        full_order_0 = TorchBackend3D.compute_integrals(full_density_batch, integral_powers)\n",
    "        full_scattering = scattering(full_density_batch)\n",
    "\n",
    "        val_density_batch = generate_weighted_sum_of_gaussians(grid, pos_batch, valence_batch, sigma)\n",
    "        val_density_batch = torch.from_numpy(val_density_batch)\n",
    "        val_density_batch = val_density_batch.to(device).float()\n",
    "        val_order_0 = TorchBackend3D.compute_integrals(val_density_batch, integral_powers)\n",
    "        val_scattering = scattering(val_density_batch)\n",
    "\n",
    "        core_density_batch = full_density_batch - val_density_batch\n",
    "        core_order_0 = TorchBackend3D.compute_integrals(core_density_batch, integral_powers)\n",
    "        core_scattering = scattering(core_density_batch)\n",
    "\n",
    "        batch_order_0 = torch.stack((full_order_0, val_order_0, core_order_0), dim=-1)\n",
    "        batch_orders_1_and_2 = torch.stack((full_scattering, val_scattering, core_scattering), dim=-1)\n",
    "        \n",
    "        order_0.append(batch_order_0)\n",
    "        orders_1_and_2.append(batch_orders_1_and_2)\n",
    "        energies.append(energie)\n",
    "        Ids.append(Id_batch)\n",
    "else:\n",
    "    order_0_test = torch.load(os.path.join(output_dir_test, 'order_0.pt'))\n",
    "    orders_1_and_2_test = torch.load(os.path.join(output_dir_test, 'orders_1_and_2.pt'))\n",
    "    Ids_test = torch.load(os.path.join(output_dir_test, 'Ids.pt'))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_SCATTERING:\n",
    "    # After the loop, concatenate the lists into single tensors\n",
    "    order_0_test = torch.cat(order_0, dim=0)  # Adjust dim as needed\n",
    "    orders_1_and_2_test = torch.cat(orders_1_and_2, dim=0)  # Adjust dim as needed\n",
    "    # energies_tensor = torch.cat(energies, dim=0)  # Adjust dim as needed\n",
    "    Ids_tensor = torch.cat(Ids, dim=0)  # Adjust dim as needed\n",
    "    torch.save(order_0_test, os.path.join(output_dir_test, \"order_0.pt\"))\n",
    "    torch.save(orders_1_and_2_test, os.path.join(output_dir_test, \"orders_1_and_2.pt\"))\n",
    "    torch.save(Ids_tensor, os.path.join(output_dir_test, \"Ids.pt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae38672",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d01e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Dataset\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, Input_Dim,Nb_Hidden_Layers, Hidden_Layers_Size_List, Output_Dim, Activation_Name):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.Input_Dim = Input_Dim\n",
    "        self.Nb_Hidden_Layers = Nb_Hidden_Layers\n",
    "        self.Hidden_Layers_Size_List = Hidden_Layers_Size_List\n",
    "        self.Output_Dim = Output_Dim\n",
    "        self.Activation_Name = Activation_Name\n",
    "        \n",
    "        # Define the layers of the MLP\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(Input_Dim, Hidden_Layers_Size_List[0]))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(Nb_Hidden_Layers - 1):\n",
    "            layers.append(self.get_activation_function(Activation_Name))\n",
    "            layers.append(nn.Linear(Hidden_Layers_Size_List[i], Hidden_Layers_Size_List[i + 1]))\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(self.get_activation_function(Activation_Name))\n",
    "        layers.append(nn.Linear(Hidden_Layers_Size_List[-1], Output_Dim))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def get_activation_function(self, activation_name):\n",
    "        if activation_name == 'ReLU':\n",
    "            return nn.ReLU()\n",
    "        elif activation_name == 'Sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        elif activation_name == 'Tanh':\n",
    "            return nn.Tanh()\n",
    "        elif activation_name == 'LeakyReLU':\n",
    "            return nn.LeakyReLU()\n",
    "        elif activation_name == 'PReLU':\n",
    "            return nn.PReLU()\n",
    "        elif activation_name == 'ELU':\n",
    "            return nn.ELU()\n",
    "        elif activation_name == 'Softmax':\n",
    "            return nn.Softmax(dim=1)\n",
    "        elif activation_name == 'GELU':\n",
    "            return nn.GELU()\n",
    "        elif activation_name == 'linear' :\n",
    "            return nn.Identity()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation function '{activation_name}' is not supported.\")\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the MLP.\n",
    "        \n",
    "        :param x: Input tensor of shape (batch_size, Input_Dim).\n",
    "        :return: Output tensor of shape (batch_size, Output_Dim).\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ff015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scattering_Dataset(Dataset):\n",
    "    def __init__(self, order_0, orders_1_and_2, energies=None, Ids=None):\n",
    "        self.order_0 = order_0\n",
    "        self.orders_1_and_2 = orders_1_and_2\n",
    "        self.energies = energies\n",
    "        self.Ids = Ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.order_0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        Ids = self.Ids[idx] if self.Ids is not None else None\n",
    "        order_0 = self.order_0[idx].reshape(-1)\n",
    "        orders_1_and_2 = self.orders_1_and_2[idx].reshape(-1)\n",
    "        energy = self.energies[idx] if self.energies is not None else None\n",
    "\n",
    "\n",
    "        Features = torch.cat((order_0, orders_1_and_2), dim=-1)\n",
    "\n",
    "        if self.energies is not None:\n",
    "            return Ids, Features, energy\n",
    "        else:\n",
    "            return Ids, Features\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dataset_Train = Scattering_Dataset(order_0_train, orders_1_and_2_train, energies_train, Ids_train)\n",
    "Dataset_Test = Scattering_Dataset(order_0_test, orders_1_and_2_test, None, Ids_test)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(Dataset_Train))\n",
    "val_size = len(Dataset_Train) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(Dataset_Train, [train_size, val_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4089b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def Train_One_Epoch(Model,Train_Loader,Optimizer,Criterion,List_Train_Losses_Per_Batches, Device):\n",
    "\n",
    "    Progress_Bar_Batch = tqdm(Train_Loader,desc=\"Batches\")\n",
    "\n",
    "    Train_Loss = 0\n",
    "    Num_Batches = 0\n",
    "    for Ids, Positions,Energies in Progress_Bar_Batch:\n",
    "        Ids = Ids.to(Device)\n",
    "        Positions = Positions.to(Device)\n",
    "        Energies = Energies.to(Device)\n",
    "\n",
    "        # Forward pass\n",
    "\n",
    "        Optimizer.zero_grad()\n",
    "\n",
    "        outputs = Model(Positions)\n",
    "\n",
    "        loss = Criterion(outputs,Energies)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        Optimizer.step()\n",
    "\n",
    "        Running_Loss = loss.item()\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        List_Train_Losses_Per_Batches.append(Running_Loss)\n",
    "\n",
    "        Progress_Bar_Batch.set_description(f\"Num Batches: {Num_Batches} Running Train Loss: {Running_Loss:.3f} \")\n",
    "\n",
    "        Train_Loss += Running_Loss\n",
    "\n",
    "        Num_Batches += 1\n",
    "\n",
    "    Train_Loss = Train_Loss/Num_Batches\n",
    "    return Train_Loss, List_Train_Losses_Per_Batches\n",
    "\n",
    "\n",
    "def Test_One_Epoch(Model,Test_Loader,Criterion,List_Test_Losses_Per_Batches, Device):\n",
    "    Progress_Bar_Batch = tqdm(Test_Loader,desc=\"Batches\",leave=False)\n",
    "\n",
    "    Test_Loss = 0\n",
    "\n",
    "    Num_Batches = 0\n",
    "\n",
    "    for Ids, images, labels in Progress_Bar_Batch:\n",
    "\n",
    "        Ids = Ids.to(Device)\n",
    "        images = images.to(Device)\n",
    "        labels = labels.to(Device)\n",
    "\n",
    "        \n",
    "        outputs = Model(images)\n",
    "\n",
    "        loss = Criterion(outputs,labels)\n",
    "\n",
    "        Running_Loss = loss.item()\n",
    "        List_Test_Losses_Per_Batches.append(Running_Loss)\n",
    "\n",
    "        Test_Loss += Running_Loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Num_Batches += 1\n",
    "\n",
    "        Progress_Bar_Batch.set_description(f\"Num Batches: {Num_Batches} Running Test Loss: {Running_Loss:.3f} \")\n",
    "\n",
    "\n",
    "    Test_Loss = Test_Loss/Num_Batches\n",
    "\n",
    "    return Test_Loss,  List_Test_Losses_Per_Batches\n",
    "\n",
    "\n",
    "def Train(Model, Train_Loader, Test_Loader, Optimizer, Criterion, Num_Epochs, Device, Save_Path=\"best_model.pth\", Best_Test_Loss=float('inf')):\n",
    "    # Set the model to training mode\n",
    "    Model.train()\n",
    "\n",
    "    # Move the model to the device\n",
    "    Model.to(Device)\n",
    "\n",
    "    List_Train_Losses_Per_Epochs = []\n",
    "    List_Test_Losses_Per_Epochs = []\n",
    "    List_Train_Losses_Per_Batches = []\n",
    "    List_Test_Losses_Per_Batches = []\n",
    "\n",
    "    Progress_Bar_Epochs = tqdm(range(Num_Epochs), desc=\"Epochs\")\n",
    "\n",
    "    for epoch in Progress_Bar_Epochs:\n",
    "        Train_Loss, List_Train_Losses_Per_Batches = Train_One_Epoch(Model, Train_Loader, Optimizer, Criterion, List_Train_Losses_Per_Batches, Device)\n",
    "\n",
    "        Test_Loss, List_Test_Losses_Per_Batches = Test_One_Epoch(Model, Test_Loader, Criterion, List_Test_Losses_Per_Batches, Device)\n",
    "\n",
    "        List_Train_Losses_Per_Epochs.append(Train_Loss)\n",
    "        List_Test_Losses_Per_Epochs.append(Test_Loss)\n",
    "\n",
    "        # Save model if test loss is the best so far\n",
    "        if Test_Loss < Best_Test_Loss:\n",
    "            Best_Test_Loss = Test_Loss\n",
    "            torch.save(Model, Save_Path)\n",
    "            print(f\"New best test loss: {Test_Loss:.3f}, model saved to {Save_Path}\")\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{Num_Epochs} Train Loss: {Train_Loss:.3f} Test Loss: {Test_Loss:.3f} \")\n",
    "\n",
    "        Progress_Bar_Epochs.set_description(f\"Epochs Train Loss: {Train_Loss:.3f} Test Loss: {Test_Loss:.3f}\")\n",
    "\n",
    "    return List_Train_Losses_Per_Epochs, List_Test_Losses_Per_Epochs, List_Train_Losses_Per_Batches, List_Test_Losses_Per_Batches\n",
    "\n",
    "\n",
    "\n",
    "def Plot_Losses(List_Train_Losses_Per_Epochs,List_Test_Losses_Per_Epochs,List_Train_Losses_Per_Batches,List_Test_Losses_Per_Batches, Save = False, Save_Path = None):\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "    axes[0, 0].plot(List_Train_Losses_Per_Epochs)\n",
    "    axes[0, 0].set_title(\"Train Losses Per Epochs\")\n",
    "    axes[0, 0].set_xlabel(\"Epochs\")\n",
    "    axes[0, 0].set_ylabel(\"Losses\")\n",
    "\n",
    "    axes[0, 1].plot(List_Test_Losses_Per_Epochs)\n",
    "    axes[0, 1].set_title(\"Test Losses Per Epochs\")\n",
    "    axes[0, 1].set_xlabel(\"Epochs\")\n",
    "    axes[0, 1].set_ylabel(\"Losses\")\n",
    "\n",
    "    axes[1, 0].plot(List_Train_Losses_Per_Batches)\n",
    "    axes[1, 0].set_title(\"Train Losses Per Batches\")\n",
    "    axes[1, 0].set_xlabel(\"Batches\")\n",
    "    axes[1, 0].set_ylabel(\"Losses\")\n",
    "\n",
    "    axes[1, 1].plot(List_Test_Losses_Per_Batches)\n",
    "    axes[1, 1].set_title(\"Test Losses Per Batches\")\n",
    "    axes[1, 1].set_xlabel(\"Batches\")\n",
    "    axes[1, 1].set_ylabel(\"Losses\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if Save:\n",
    "        plt.savefig(Save_Path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3294431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Nb_Hidden_Layers = 1\n",
    "Hidden_Layers_Size_List = [500]\n",
    "Input_Dim = 375\n",
    "Ouput_Dim = 1\n",
    "\n",
    "Activation_Name = 'Identity'\n",
    "\n",
    "Model = MLP(Input_Dim, Nb_Hidden_Layers, Hidden_Layers_Size_List, Ouput_Dim, Activation_Name)\n",
    "\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "Optimizer = torch.optim.Adam(Model.parameters(), lr=3e-4)\n",
    "\n",
    "Criterion = nn.MSELoss()\n",
    "\n",
    "# Define the device\n",
    "Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "Model = Model.to(Device)\n",
    "\n",
    "# Create the DataLoaders\n",
    "Train_DataLoader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "Val_DataLoader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "Test_DataLoader = DataLoader(Dataset_Test, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train(Model, Train_DataLoader, Val_DataLoader, Optimizer, Criterion, Num_Epochs=100, Device=Device, Save_Path=\"best_model.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
